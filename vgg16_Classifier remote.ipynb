{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artificialcoder02/Vgg16_Image_Classifier/blob/main/vgg16_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGJXvLUiYLuL",
        "outputId": "4eb79332-ecab-4841-d744-965607f8e56d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Mar 26 14:39:41 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 531.41                 Driver Version: 531.41       CUDA Version: 12.1     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1650 Ti    WDDM | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   50C    P8                5W /  N/A|    321MiB /  4096MiB |     34%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A      1720    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A      5612    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
            "|    0   N/A  N/A      9396    C+G   ...on\\111.0.1661.54\\msedgewebview2.exe    N/A      |\n",
            "|    0   N/A  N/A     10356    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     11336    C+G   ...x64__qmba6cd70vzyy\\ArmouryCrate.exe    N/A      |\n",
            "|    0   N/A  N/A     12120    C+G   ...on\\111.0.1661.54\\msedgewebview2.exe    N/A      |\n",
            "|    0   N/A  N/A     13492    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6icOTaoetHV",
        "outputId": "932ba49e-8cad-4d8c-8617-cadb58c82716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGo_7V0ye8h1"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kcG-2aGne7mn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
            "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.23.5 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.12.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
            "Collecting tensorflow-intel==2.12.0\n",
            "  Downloading tensorflow_intel-2.12.0-cp39-cp39-win_amd64.whl (272.8 MB)\n",
            "     -------------------------------------- 272.8/272.8 MB 5.4 MB/s eta 0:00:00\n",
            "Collecting libclang>=13.0.0\n",
            "  Downloading libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
            "     --------------------------------------- 24.4/24.4 MB 10.4 MB/s eta 0:00:00\n",
            "Collecting numpy<1.24,>=1.22\n",
            "  Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
            "     --------------------------------------- 14.7/14.7 MB 11.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
            "Collecting astunparse>=1.6.0\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting tensorboard<2.13,>=2.12\n",
            "  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
            "     ---------------------------------------- 5.6/5.6 MB 10.9 MB/s eta 0:00:00\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
            "     ---------------------------------------- 1.5/1.5 MB 11.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: setuptools in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (63.4.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.3.0)\n",
            "Collecting jax>=0.3.15\n",
            "  Downloading jax-0.4.6.tar.gz (1.2 MB)\n",
            "     ---------------------------------------- 1.2/1.2 MB 11.3 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting grpcio<2.0,>=1.24.3\n",
            "  Downloading grpcio-1.51.3-cp39-cp39-win_amd64.whl (3.7 MB)\n",
            "     ---------------------------------------- 3.7/3.7 MB 11.3 MB/s eta 0:00:00\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
            "  Downloading protobuf-4.22.1-cp39-cp39-win_amd64.whl (420 kB)\n",
            "     ------------------------------------- 420.6/420.6 kB 13.2 MB/s eta 0:00:00\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "     ------------------------------------- 440.7/440.7 kB 13.5 MB/s eta 0:00:00\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
            "Collecting absl-py>=1.0.0\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "     -------------------------------------- 126.5/126.5 kB 7.3 MB/s eta 0:00:00\n",
            "Collecting google-pasta>=0.1.1\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
            "Collecting keras<2.13,>=2.12.0\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "     ---------------------------------------- 1.7/1.7 MB 11.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.5 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.9.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3.4)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.16.3-py2.py3-none-any.whl (177 kB)\n",
            "     ------------------------------------- 177.5/177.5 kB 10.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.3)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Downloading tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.9.14)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\rctuh\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "     -------------------------------------- 151.7/151.7 kB 8.8 MB/s eta 0:00:00\n",
            "Building wheels for collected packages: jax\n",
            "  Building wheel for jax (setup.py): started\n",
            "  Building wheel for jax (setup.py): finished with status 'done'\n",
            "  Created wheel for jax: filename=jax-0.4.6-py3-none-any.whl size=1432714 sha256=43a883fb6bc60cc55998dfde636c55cce761268c2657f88d0a0406f324f295c4\n",
            "  Stored in directory: c:\\users\\rctuh\\appdata\\local\\pip\\cache\\wheels\\68\\2c\\93\\17deec4d117dc0675ed79e8e2af1e62fb1c41ed3955c540de0\n",
            "Successfully built jax\n",
            "Installing collected packages: tensorboard-plugin-wit, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, oauthlib, numpy, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, opt-einsum, google-auth, jax, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.16.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.3 jax-0.4.6 keras-2.12.0 libclang-16.0.0 numpy-1.23.5 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.22.1 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.2.0\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Input,Lambda,Dense,Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "At7SSQfxlzLp"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH=r'C:\\Users\\rctuh\\Desktop\\minor projects\\Vgg16_Image_Classifier\\cats_and_dogs\\cats_and_dogs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjzCwbZUmEUp",
        "outputId": "4f16db6c-3dd1-4bf4-8241-42c1337f9e0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\rctuh\\\\Desktop\\\\minor projects\\\\Vgg16_Image_Classifier'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GrMESrVvmGO_",
        "outputId": "0e735b74-b71d-444f-b25f-a9b2f453a66f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/cats_and_dogs'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os \n",
        "os.chdir(ROOT_PATH)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6CUAelKmcFx"
      },
      "source": [
        "#Resizing all images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GQf8CKghmWnC"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE=[224,224]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "O27s-puAmmSa"
      },
      "outputs": [],
      "source": [
        "train_path=r'C:\\Users\\rctuh\\Desktop\\minor projects\\Vgg16_Image_Classifier\\cats_and_dogs\\cats_and_dogs\\train'\n",
        "valid_path=r'C:\\Users\\rctuh\\Desktop\\minor projects\\Vgg16_Image_Classifier\\cats_and_dogs\\cats_and_dogs\\test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvFgPy51mzEI"
      },
      "source": [
        "#Importing VGG16 library and add preprocesing layer in front of the VGG16.\n",
        "#Here we will se ImageNet weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9X85mZNm-V-",
        "outputId": "8433194a-55c9-4d2d-b1d0-a8502dba6fc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 6s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vgg16=VGG16(input_shape=IMAGE_SIZE+[3],weights='imagenet',include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaNaj-pknMDp",
        "outputId": "68d37dfe-c113-42a2-b52e-7c3925912422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x0000023BC59F5CF0>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000023BC6E4C9D0>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000023BC6E4CFA0>\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000023BC6F521D0>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000023BC6E4D5D0>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000023BC6F53B50>\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000023BC6F88D30>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000023BC6F7AB90>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000023BC6F8BCA0>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000023BC6F8A5F0>\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000023BC6F7B190>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000023BC6F88610>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000023BC6E4E950>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000023BC6FAB130>\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000023BC6FC2DD0>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000023BC6FC39D0>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000023BC6FD6950>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000023BC6FD6F20>\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x0000023BC700CF40>\n"
          ]
        }
      ],
      "source": [
        "for layers in vgg16.layers:\n",
        "  print(layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqPR4-3ordR7"
      },
      "source": [
        "###Setting layer.trainable to False moves all the layer's weights from trainable to non-trainable. This is called \"freezing\" the layer: the state of a frozen layer won't be updated during training (either when training with fit() or when training with any custom loop that relies on trainable_weights to apply gradient updates)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "inkzdXgJph_h"
      },
      "outputs": [],
      "source": [
        "for layer in vgg16.layers:\n",
        "  layer.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS7XhocSprfD",
        "outputId": "b3bedd79-e843-4dd7-fd04-c767e14a0be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_1 False\n",
            "block1_conv1 False\n",
            "block1_conv2 False\n",
            "block1_pool False\n",
            "block2_conv1 False\n",
            "block2_conv2 False\n",
            "block2_pool False\n",
            "block3_conv1 False\n",
            "block3_conv2 False\n",
            "block3_conv3 False\n",
            "block3_pool False\n",
            "block4_conv1 False\n",
            "block4_conv2 False\n",
            "block4_conv3 False\n",
            "block4_pool False\n",
            "block5_conv1 False\n",
            "block5_conv2 False\n",
            "block5_conv3 False\n",
            "block5_pool False\n"
          ]
        }
      ],
      "source": [
        "for layer in vgg16.layers:\n",
        "  print(layer.name,layer.trainable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lVdF3pSp7qB"
      },
      "source": [
        "#Vgg16 Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc3WdCr4p0-U",
        "outputId": "37020d40-44f6-4df2-ac4a-876bf0c494b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vgg16.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qtQZ54qp7LJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM5LqqKKyCNaWLTUYJiqf2q",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
